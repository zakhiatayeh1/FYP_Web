{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    product  quantity date_ordered  price\n",
      "0  Mountain       120   2023-01-01    500\n",
      "1      Road       150   2023-01-02    800\n",
      "2    Hybrid       130   2023-01-03    650\n",
      "3  Mountain       140   2023-01-04    520\n",
      "4      Road       160   2023-01-05    820\n",
      "5    Hybrid       135   2023-01-06    660\n",
      "6  Mountain       150   2023-01-07    530\n",
      "7      Road       165   2023-01-08    830\n",
      "8    Hybrid       140   2023-01-09    670\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Sample data creation\n",
    "data = {\n",
    "    'product': ['Mountain', 'Road', 'Hybrid', 'Mountain', 'Road', 'Hybrid', 'Mountain', 'Road', 'Hybrid'],\n",
    "    'quantity': [120, 150, 130, 140, 160, 135, 150, 165, 140],\n",
    "    'date_ordered': [datetime(2023, 1, 1) + timedelta(days=i) for i in range(9)],\n",
    "    'price': [500, 800, 650, 520, 820, 660, 530, 830, 670]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Configuring preprocessing pipeline\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(), ['product']),\n",
    "    ('scaler', StandardScaler(), ['quantity', 'price'])\n",
    "])\n",
    "\n",
    "# Fitting and transforming the data\n",
    "processed_data = column_transformer.fit_transform(df)\n",
    "\n",
    "# Creating sequences\n",
    "def create_sequences(data, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(data) - 1:\n",
    "            break\n",
    "        seq_x, seq_y = data[i:end_ix], data[end_ix, 1]  # Assuming the next quantity to be predicted\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "n_steps = 3  # Using last 3 days to predict the next day\n",
    "X, y = create_sequences(processed_data, n_steps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Input\n",
    "\n",
    "# Define the model using an Input layer\n",
    "model = Sequential([\n",
    "    Input(shape=(n_steps, X.shape[2])),  # Clearly define the input shape\n",
    "    SimpleRNN(50, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Now you can proceed with model training\n",
    "# model.fit(X, y, epochs=30, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 167ms/step - loss: 0.1721 - mae: 0.3238 - val_loss: 0.2207 - val_mae: 0.4153\n",
      "Epoch 2/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1495 - mae: 0.3058 - val_loss: 0.1895 - val_mae: 0.3826\n",
      "Epoch 3/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1262 - mae: 0.2710 - val_loss: 0.1657 - val_mae: 0.3568\n",
      "Epoch 4/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1018 - mae: 0.2418 - val_loss: 0.1435 - val_mae: 0.3284\n",
      "Epoch 5/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0891 - mae: 0.2241 - val_loss: 0.1230 - val_mae: 0.3013\n",
      "Epoch 6/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0776 - mae: 0.2110 - val_loss: 0.1091 - val_mae: 0.2840\n",
      "Epoch 7/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0630 - mae: 0.1923 - val_loss: 0.0960 - val_mae: 0.2656\n",
      "Epoch 8/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0554 - mae: 0.1820 - val_loss: 0.0818 - val_mae: 0.2468\n",
      "Epoch 9/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0430 - mae: 0.1579 - val_loss: 0.0699 - val_mae: 0.2276\n",
      "Epoch 10/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0414 - mae: 0.1569 - val_loss: 0.0585 - val_mae: 0.2040\n",
      "Epoch 11/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0376 - mae: 0.1504 - val_loss: 0.0489 - val_mae: 0.1857\n",
      "Epoch 12/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0302 - mae: 0.1325 - val_loss: 0.0413 - val_mae: 0.1706\n",
      "Epoch 13/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0271 - mae: 0.1275 - val_loss: 0.0352 - val_mae: 0.1444\n",
      "Epoch 14/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0278 - mae: 0.1303 - val_loss: 0.0318 - val_mae: 0.1289\n",
      "Epoch 15/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0242 - mae: 0.1226 - val_loss: 0.0294 - val_mae: 0.1260\n",
      "Epoch 16/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0223 - mae: 0.1178 - val_loss: 0.0267 - val_mae: 0.1192\n",
      "Epoch 17/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0203 - mae: 0.1096 - val_loss: 0.0247 - val_mae: 0.1205\n",
      "Epoch 18/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0174 - mae: 0.1029 - val_loss: 0.0243 - val_mae: 0.1302\n",
      "Epoch 19/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0154 - mae: 0.0963 - val_loss: 0.0254 - val_mae: 0.1385\n",
      "Epoch 20/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0157 - mae: 0.0971 - val_loss: 0.0276 - val_mae: 0.1417\n",
      "Epoch 21/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0129 - mae: 0.0874 - val_loss: 0.0300 - val_mae: 0.1378\n",
      "Epoch 22/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0133 - mae: 0.0892 - val_loss: 0.0317 - val_mae: 0.1433\n",
      "Epoch 23/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0129 - mae: 0.0886 - val_loss: 0.0267 - val_mae: 0.1327\n",
      "Epoch 24/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0204 - val_mae: 0.1218\n",
      "Epoch 25/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0083 - mae: 0.0702 - val_loss: 0.0179 - val_mae: 0.1147\n",
      "Epoch 26/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0081 - mae: 0.0713 - val_loss: 0.0167 - val_mae: 0.1064\n",
      "Epoch 27/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0068 - mae: 0.0648 - val_loss: 0.0183 - val_mae: 0.1008\n",
      "Epoch 28/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0080 - mae: 0.0668 - val_loss: 0.0226 - val_mae: 0.1090\n",
      "Epoch 29/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0082 - mae: 0.0680 - val_loss: 0.0190 - val_mae: 0.0975\n",
      "Epoch 30/30\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0058 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.1077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0645 - mae: 0.2160\n",
      "Test Loss: 0.06454640626907349, Test MAE: 0.2160031944513321\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Input\n",
    "\n",
    "# Creating a sample dataset\n",
    "np.random.seed(42)\n",
    "dates = [datetime(2023, 1, 1) + timedelta(days=i) for i in range(100)]\n",
    "products = np.random.choice(['Mountain', 'Road', 'Hybrid'], size=100)\n",
    "quantities = np.random.randint(100, 200, size=100)\n",
    "prices = np.random.normal(1, 0.1, size=100) * np.where(products == 'Mountain', 500, np.where(products == 'Road', 800, 650))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date_ordered': dates,\n",
    "    'product': products,\n",
    "    'quantity': quantities,\n",
    "    'price': prices\n",
    "})\n",
    "\n",
    "# Preprocessing\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(), ['product']),\n",
    "    ('scaler', StandardScaler(), ['quantity', 'price'])\n",
    "])\n",
    "\n",
    "data = column_transformer.fit_transform(df)\n",
    "n_steps = 7\n",
    "n_features = data.shape[1]\n",
    "\n",
    "# Create sequences\n",
    "def create_sequences(data, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        end_ix = i + n_steps\n",
    "        seq_x, seq_y = data[i:end_ix], data[end_ix - 1, 1]  # Use quantity of the last timestep as label\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(data, n_steps)\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model definition\n",
    "model = Sequential([\n",
    "    Input(shape=(n_steps, n_features)),\n",
    "    SimpleRNN(50, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_split=0.1)\n",
    "\n",
    "# Model evaluation\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
